{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100S-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Collecting certifi>=2023.7.22 (from kaggle)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from kaggle) (1.26.16)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: webencodings in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->kaggle) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->kaggle) (3.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105789 sha256=edbd5823885c5552e312b9bd46d807ba09aa243bca7d8c49f21e2a0c713edef8\n",
      "  Stored in directory: /mnt/ufs18/home-086/madired3/.cache/pip/wheels/ff/55/fb/b27a466be754d2a06ffe0e37b248d844f090a63b51becea85d\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, tqdm, python-slugify, certifi, bleach, kaggle\n",
      "Successfully installed bleach-6.2.0 certifi-2024.8.30 kaggle-1.6.17 python-slugify-8.0.4 text-unidecode-1.3 tqdm-4.67.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167802\n",
      "37265\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(len(os.listdir(\"./dataset_20210629145407_top_600/annotations\")))\n",
    "print(len(os.listdir(\"./dataset_20210629145407_top_600/images\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove images and labels of index > 30000\n",
    "i=0\n",
    "for i, label_file in enumerate(sorted(os.listdir(\"./dataset_20210629145407_top_600/annotations\"))):\n",
    "    if i>30000:\n",
    "        src_image_path = os.path.join(\"./dataset_20210629145407_top_600/annotations\", label_file)\n",
    "        os.remove(src_image_path)\n",
    "\n",
    "for i, image_file in enumerate(sorted(os.listdir(\"./dataset_20210629145407_top_600/images\"))):\n",
    "    if i>30000:\n",
    "        src_image_path = os.path.join(\"./dataset_20210629145407_top_600/images\", image_file)\n",
    "        os.remove(src_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/dreamfactor/biggest-lego-dataset-600-parts\n",
      "License(s): CC0-1.0\n",
      "Downloading biggest-lego-dataset-600-parts.zip to /mnt/ufs18/home-086/madired3/cse841\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 7.68G/7.68G [01:37<00:00, 83.6MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.68G/7.68G [01:37<00:00, 84.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d dreamfactor/biggest-lego-dataset-600-parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_20210629145407_top_600/images/39037eb4-d9df-11eb-a530-3497f683a169.jpg:  write error (disk full?).  Continue? (y/n/^C) "
     ]
    }
   ],
   "source": [
    "!unzip -q biggest-lego-dataset-600-parts.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing ./dataset_20210629145407_top_600/annotations/225122c6-db87-11eb-bf78-3497f683a169.xml: not well-formed (invalid token): line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "def pascal_voc_to_yolo(annotations_dir, image_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Converts PASCAL VOC format annotations to YOLO format.\n",
    "\n",
    "    Args:\n",
    "        annotations_dir: Path to the directory containing PASCAL VOC XML files.\n",
    "        image_dir: Path to the directory containing the corresponding images.\n",
    "        output_dir: Path to the directory to save the YOLO text files.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "    category_map = {} # Dictionary to store category names and their indices\n",
    "    category_id = 0\n",
    "\n",
    "\n",
    "    for filename in os.listdir(annotations_dir):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            annotation_path = os.path.join(annotations_dir, filename)\n",
    "            try:\n",
    "                tree = ET.parse(annotation_path)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                image_name = root.find(\"filename\").text\n",
    "                image_path = os.path.join(image_dir, image_name)  # Construct image path\n",
    "                width = int(root.find(\"size\").find(\"width\").text)\n",
    "                height = int(root.find(\"size\").find(\"height\").text)\n",
    "\n",
    "\n",
    "                yolo_annotations = []\n",
    "\n",
    "                for obj in root.findall(\"object\"):\n",
    "                    category_name = obj.find(\"name\").text\n",
    "                        # category_id += 1\n",
    "\n",
    "                    bbox = obj.find(\"bndbox\")\n",
    "                    xmin = int(bbox.find(\"xmin\").text)\n",
    "                    ymin = int(bbox.find(\"ymin\").text)\n",
    "                    xmax = int(bbox.find(\"xmax\").text)\n",
    "                    ymax = int(bbox.find(\"ymax\").text)\n",
    "\n",
    "\n",
    "                    x_center = (xmin + xmax) / (2 * width)\n",
    "                    y_center = (ymin + ymax) / (2 * height)\n",
    "                    w_norm = (xmax - xmin) / width\n",
    "                    h_norm = (ymax - ymin) / height\n",
    "\n",
    "                    yolo_annotation = f\"0 {x_center} {y_center} {w_norm} {h_norm}\\n\"\n",
    "                    yolo_annotations.append(yolo_annotation)\n",
    "\n",
    "\n",
    "                output_filename = filename[:-4] + \".txt\"  # Replace .xml with .txt\n",
    "                output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "                with open(output_path, \"w\") as f:\n",
    "                    f.writelines(yolo_annotations)\n",
    "\n",
    "            except ET.ParseError as e:\n",
    "                print(f\"Error parsing {annotation_path}: {e}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Image file not found: {image_path}\")  # Handle missing images\n",
    "\n",
    "\n",
    "    # Create a categories.txt file (optional but useful)\n",
    "    categories_path = os.path.join(output_dir, \"categories.txt\")\n",
    "    with open(categories_path, \"w\") as f:\n",
    "        for category_name, category_id in category_map.items():\n",
    "            f.write(f\"{category_name}\\n\")\n",
    "\n",
    "# Example Usage\n",
    "annotations_dir = \"./dataset_20210629145407_top_600/annotations/\"\n",
    "image_dir = \"./dataset_20210629145407_top_600/images/\"  # Path to the directory with images\n",
    "output_dir = \"./dataset_20210629145407_top_600/labels/\"\n",
    "pascal_voc_to_yolo(annotations_dir, image_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset_20210629145407_top_600/images/ffffefc2-da91-11eb-8c79-3497f683a169.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mmove(src_label_path, dest_label_path)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m       os\u001b[38;5;241m.\u001b[39mremove(src_image_path)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles have been successfully split into train and val folders.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset_20210629145407_top_600/images/ffffefc2-da91-11eb-8c79-3497f683a169.jpg'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define your directories\n",
    "annotations_dir = \"./dataset_20210629145407_top_600/annotations/\"\n",
    "image_dir = \"./dataset_20210629145407_top_600/images/\"\n",
    "output_dir = \"./dataset_20210629145407_top_600/labels/\"\n",
    "\n",
    "# Define train and validation directories\n",
    "train_image_dir = \"./datasets/images/train/\"\n",
    "val_image_dir = \"./datasets/images/val/\"\n",
    "train_label_dir = \"./datasets/labels/train/\"\n",
    "val_label_dir = \"./datasets/labels/val/\"\n",
    "\n",
    "# Create train/val directories if they don't exist\n",
    "os.makedirs(train_image_dir, exist_ok=True)\n",
    "os.makedirs(val_image_dir, exist_ok=True)\n",
    "os.makedirs(train_label_dir, exist_ok=True)\n",
    "os.makedirs(val_label_dir, exist_ok=True)\n",
    "\n",
    "# Get a sorted list of image and label files\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "label_files = sorted(os.listdir(output_dir))\n",
    "\n",
    "# Move images to train and val folders\n",
    "for i, image_file in enumerate(image_files):\n",
    "    src_image_path = os.path.join(image_dir, image_file)\n",
    "    if i < 2000:\n",
    "        dest_image_path = os.path.join(val_image_dir, image_file)\n",
    "        shutil.move(src_image_path, dest_image_path)\n",
    "    elif i<=22000:\n",
    "        dest_image_path = os.path.join(train_image_dir, image_file)\n",
    "        shutil.move(src_image_path, dest_image_path)\n",
    "    else:\n",
    "        os.remove(src_image_path)\n",
    "\n",
    "    \n",
    "# Move labels to train and val folders\n",
    "for i, label_file in enumerate(label_files):\n",
    "    src_label_path = os.path.join(output_dir, label_file)\n",
    "    if i < 2000:\n",
    "        dest_label_path = os.path.join(val_label_dir, label_file)\n",
    "        shutil.move(src_label_path, dest_label_path)    \n",
    "    elif i<=22000:\n",
    "        dest_label_path = os.path.join(train_label_dir, label_file)\n",
    "        shutil.move(src_label_path, dest_label_path)\n",
    "    else:\n",
    "      os.remove(src_image_path)\n",
    "    \n",
    "\n",
    "print(\"Files have been successfully split into train and val folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167802\n",
      "167800\n"
     ]
    }
   ],
   "source": [
    "print(len(label_files))\n",
    "print(len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.31 ğŸš€ Python-3.11.3 torch-2.5.1+cu124 CUDA:0 (Tesla V100S-PCIE-32GB, 32494MiB)\n",
      "Setup complete âœ… (48 CPUs, 187.3 GB RAM, 12.8/25.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# %pip install ultralytics\n",
    "%pip install -U ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.32 ğŸš€ Python-3.11.3 torch-2.5.1+cu124 CUDA:0 (Tesla V100S-PCIE-32GB, 32494MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=./yolo11l.pt, data=./lego.yaml, epochs=20, time=None, patience=100, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train15, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train15\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLO11l summary: 631 layers, 25,311,251 parameters, 25,311,235 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/ufs18/home-086/madired3/cse841/datasets/labels/train.cache... 20000 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20001/20001 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla V100S-PCIE-32GB) 31.73G total, 0.24G reserved, 0.22G allocated, 31.27G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    25311251       87.27         0.960         69.96         151.2        (1, 3, 640, 640)                    list\n",
      "    25311251       174.5         1.625         59.57         78.83        (2, 3, 640, 640)                    list\n",
      "    25311251       349.1         2.898         273.8         78.28        (4, 3, 640, 640)                    list\n",
      "    25311251       698.2         5.450         70.39         86.54        (8, 3, 640, 640)                    list\n",
      "    25311251        1396        10.597         84.96         116.2       (16, 3, 640, 640)                    list\n",
      "    25311251        2793        20.321         168.8           194       (32, 3, 640, 640)                    list\n",
      "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 86.19 MiB is free. Including non-PyTorch memory, this process has 31.64 GiB memory in use. Of the allocated memory 31.08 GiB is allocated by PyTorch, and 141.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 29 for CUDA:0 19.00G/31.73G (60%) âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/ufs18/home-086/madired3/cse841/datasets/labels/train.cache... 20000 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20001/20001 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/ufs18/home-086/madired3/cse841/datasets/labels/val.cache... 2000 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train15/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.000453125), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train15\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      18.8G     0.6422     0.6858      1.102         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:36<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:14<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.906      0.861      0.918      0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20        19G     0.6232      0.598       1.09         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:22<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.928      0.902      0.952      0.862\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      18.9G     0.6039     0.5809      1.078        103        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:18<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.912      0.777      0.853      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20        19G     0.5711     0.5405       1.06        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:19<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:14<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.956      0.928       0.97      0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20        19G     0.5408     0.5048      1.045        116        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:18<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.962      0.941      0.979      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20        19G     0.5091     0.4743      1.026         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:16<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.964      0.951      0.982      0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      18.9G     0.4973     0.4556      1.017        109        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:16<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.972       0.95      0.984      0.937\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20        19G     0.4839     0.4427      1.014        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:16<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.977      0.956      0.986      0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      18.9G     0.4703     0.4279      1.005         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:17<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.976      0.961      0.988      0.949\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20        19G     0.4598     0.4166     0.9983        101        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:16<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.979      0.956      0.988      0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      18.9G     0.3824     0.3065     0.9399         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:18<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.972      0.967       0.99      0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      18.9G     0.3729     0.2911      0.935         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:16<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.979      0.963      0.991      0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      18.9G     0.3623     0.2787     0.9269         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:16<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566       0.98       0.97      0.992      0.962\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      18.9G     0.3514     0.2722     0.9213         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:16<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.982      0.966      0.992      0.962\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      18.9G     0.3459     0.2609     0.9189         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:17<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.983       0.97      0.993      0.965\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      18.9G     0.3353     0.2502     0.9114         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:18<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:14<00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.982      0.971      0.993      0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      18.9G     0.3287     0.2432     0.9088         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:16<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.986      0.969      0.993      0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      18.9G     0.3189     0.2305     0.9024         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:16<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.988      0.971      0.993      0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      18.9G      0.308     0.2187      0.896         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:17<00:00,  2.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:13<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.987      0.973      0.994       0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      18.9G     0.2996     0.2106     0.8921         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [05:19<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:14<00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.983      0.977      0.994      0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 1.855 hours.\n",
      "Optimizer stripped from runs/detect/train15/weights/last.pt, 51.2MB\n",
      "Optimizer stripped from runs/detect/train15/weights/best.pt, 51.2MB\n",
      "\n",
      "Validating runs/detect/train15/weights/best.pt...\n",
      "Ultralytics 8.3.32 ğŸš€ Python-3.11.3 torch-2.5.1+cu124 CUDA:0 (Tesla V100S-PCIE-32GB, 32494MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,280,083 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:16<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2000       6566      0.983      0.977      0.994      0.971\n",
      "Speed: 0.1ms preprocess, 3.9ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train15\u001b[0m\n",
      "Model saved as: yolo11x_trained.pt\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv11 model\n",
    "model = YOLO('./yolo11l.pt')  # Replace with the path to yolov11.pt\n",
    "\n",
    "# Train the model\n",
    "model.train(data='./lego.yaml', epochs=20, batch=-1, imgsz=640)\n",
    "\n",
    "# Save the trained model\n",
    "trained_model_path = 'yolo11x_trained.pt'\n",
    "model.save(trained_model_path)\n",
    "\n",
    "print(f\"Model saved as: {trained_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/ufs18/home-086/madired3/cse841/000a2e34-d9d5-11eb-b337-3497f683a169.jpg: 640x640 4 legos, 23.2ms\n",
      "Speed: 3.1ms preprocess, 23.2ms inference, 11.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Detections:  4\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'lego'}\n",
      "obb: None\n",
      "orig_img: array([[[ 21,  48,  82],\n",
      "        [ 21,  48,  82],\n",
      "        [ 21,  48,  82],\n",
      "        ...,\n",
      "        [ 83, 130, 174],\n",
      "        [ 84, 131, 175],\n",
      "        [ 84, 131, 175]],\n",
      "\n",
      "       [[ 22,  49,  83],\n",
      "        [ 23,  50,  84],\n",
      "        [ 25,  52,  86],\n",
      "        ...,\n",
      "        [ 77, 124, 168],\n",
      "        [ 79, 126, 170],\n",
      "        [ 78, 127, 171]],\n",
      "\n",
      "       [[ 26,  53,  87],\n",
      "        [ 28,  55,  89],\n",
      "        [ 30,  57,  91],\n",
      "        ...,\n",
      "        [ 69, 118, 162],\n",
      "        [ 71, 120, 164],\n",
      "        [ 71, 122, 165]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 39,  68,  99],\n",
      "        [ 39,  68,  99],\n",
      "        [ 38,  67,  98],\n",
      "        ...,\n",
      "        [ 67,  99, 134],\n",
      "        [ 68, 100, 135],\n",
      "        [ 69, 101, 136]],\n",
      "\n",
      "       [[ 39,  68,  99],\n",
      "        [ 38,  67,  98],\n",
      "        [ 37,  66,  97],\n",
      "        ...,\n",
      "        [ 67,  99, 134],\n",
      "        [ 68, 100, 135],\n",
      "        [ 69, 101, 136]],\n",
      "\n",
      "       [[ 39,  68,  99],\n",
      "        [ 38,  67,  98],\n",
      "        [ 37,  66,  97],\n",
      "        ...,\n",
      "        [ 67,  99, 134],\n",
      "        [ 68, 100, 135],\n",
      "        [ 69, 101, 136]]], dtype=uint8)\n",
      "orig_shape: (600, 600)\n",
      "path: '/mnt/ufs18/home-086/madired3/cse841/000a2e34-d9d5-11eb-b337-3497f683a169.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict'\n",
      "speed: {'preprocess': 3.0930042266845703, 'inference': 23.241519927978516, 'postprocess': 11.46078109741211}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO  # Import YOLO framework\n",
    "\n",
    "# Load the YOLOv11 model\n",
    "model = YOLO(\"yolo11x_trained.pt\")  # Path to your trained model\n",
    "\n",
    "# Perform inference on the image\n",
    "results = model(\"./dataset_20210629145407_top_600/JPEGImages/0a0abab6-daf8-11eb-a7fc-3497f683a169.jpg\")  # Path to the test image\n",
    "\n",
    "# Print detections\n",
    "print(\"Detections: \",len(results[0].boxes))\n",
    "\n",
    "for result in results:\n",
    "    print(result)  # Adjust this to inspect bounding boxes, class scores, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.], device='cuda:0')\n",
      "conf: tensor([0.9719], device='cuda:0')\n",
      "data: tensor([[182.2321, 363.4385, 421.9596, 480.0490,   0.9719,   0.0000]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (600, 600)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[302.0959, 421.7437, 239.7275, 116.6105]], device='cuda:0')\n",
      "xywhn: tensor([[0.5035, 0.7029, 0.3995, 0.1944]], device='cuda:0')\n",
      "xyxy: tensor([[182.2321, 363.4385, 421.9596, 480.0490]], device='cuda:0')\n",
      "xyxyn: tensor([[0.3037, 0.6057, 0.7033, 0.8001]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(result[0].boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting jupyter\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: notebook in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter) (7.2.2)\n",
      "Requirement already satisfied: jupyter-console in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter) (4.2.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipykernel->jupyter) (1.8.8)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipykernel->jupyter) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from ipykernel->jupyter) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from ipykernel->jupyter) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=24 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipykernel->jupyter) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipykernel->jupyter) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipywidgets->jupyter) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipywidgets->jupyter) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-console->jupyter) (3.0.48)\n",
      "Requirement already satisfied: pygments in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jupyter-console->jupyter) (2.15.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyterlab->jupyter) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyterlab->jupyter) (0.27.2)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jupyterlab->jupyter) (3.1.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyterlab->jupyter) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyterlab->jupyter) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/site-packages (from jupyterlab->jupyter) (67.7.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /mnt/home/madired3/.local/lib/python3.11/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /mnt/home/madired3/.local/lib/python3.11/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from nbconvert->jupyter) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from nbconvert->jupyter) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: webencodings in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: anyio in /mnt/home/madired3/.local/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in /mnt/home/madired3/.local/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.4)\n",
      "Requirement already satisfied: sniffio in /mnt/home/madired3/.local/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.14.0)\n",
      "Requirement already satisfied: decorator in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack-data in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.8.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.21.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.12.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.9.28)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.31.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.20.0)\n",
      "Requirement already satisfied: wcwidth in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.6)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /mnt/home/madired3/.local/lib/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.21.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.26.16)\n",
      "Requirement already satisfied: executing>=1.2.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /mnt/home/madired3/.local/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: fqdn in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/software-current/2023.06/x86_64/intel/skylake_avx512/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /mnt/home/madired3/.local/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.9.0.20241003)\n",
      "Installing collected packages: jsonschema, jupyter\n",
      "Successfully installed jsonschema-4.23.0 jupyter-1.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 28 17:49:08 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100S-PCIE-32GB          Off |   00000000:3D:00.0 Off |                  Off |\n",
      "| N/A   38C    P0             54W /  250W |   20572MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100S-PCIE-32GB          Off |   00000000:3E:00.0 Off |                  Off |\n",
      "| N/A   38C    P0             52W /  250W |     312MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  Tesla V100S-PCIE-32GB          Off |   00000000:88:00.0 Off |                  Off |\n",
      "| N/A   37C    P0             37W /  250W |     312MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  Tesla V100S-PCIE-32GB          Off |   00000000:89:00.0 Off |                  Off |\n",
      "| N/A   37C    P0             37W /  250W |     312MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    863494      C   ...conda3/envs/pytorch-cuda/bin/python        448MiB |\n",
      "|    0   N/A  N/A   2865617      C   ...ware/Miniforge3/24.3.0-0/bin/python      20112MiB |\n",
      "|    1   N/A  N/A   2865617      C   ...ware/Miniforge3/24.3.0-0/bin/python        306MiB |\n",
      "|    2   N/A  N/A   2865617      C   ...ware/Miniforge3/24.3.0-0/bin/python        306MiB |\n",
      "|    3   N/A  N/A   2865617      C   ...ware/Miniforge3/24.3.0-0/bin/python        306MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.31 ğŸš€ Python-3.11.3 torch-2.5.1+cu124 CUDA:0 (Tesla V100S-PCIE-32GB, 32494MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,280,083 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/ufs18/home-086/madired3/cse841/datasets/labels/val.cache... 100 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        100        330      0.993      0.955       0.99      0.963\n",
      "Speed: 0.3ms preprocess, 12.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train22\u001b[0m\n",
      "Validation results:\n",
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x14eec5d75850>\n",
      "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
      "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,\n",
      "            0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,\n",
      "            0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99683,     0.99369,     0.99369,     0.99369,      0.9906,      0.9906,      0.9906,     0.98452,     0.98452,     0.98452,     0.98452,     0.98452,     0.98452,     0.97853,     0.97853,     0.97853,\n",
      "            0.96677,     0.96677,     0.96677,     0.96108,     0.96108,     0.96108,     0.95549,     0.95549,     0.95549,     0.93353,     0.93353,     0.93353,     0.88043,     0.88043,     0.88043,     0.84635,     0.84635,     0.84635,     0.73756,     0.73756,     0.73756,     0.70323,     0.70323,\n",
      "            0.70323,     0.43501,     0.43501,     0.43501,     0.38788,     0.32323,     0.25859,     0.19394,     0.12929,    0.064647,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.56164,     0.56268,     0.67968,     0.72327,      0.7558,     0.77939,     0.79422,     0.80868,     0.81851,     0.82887,     0.83236,     0.84137,     0.84392,     0.84429,     0.85152,     0.85771,     0.86225,     0.86602,     0.86782,     0.86918,     0.86996,     0.87154,     0.87329,\n",
      "            0.87723,     0.87795,     0.87932,     0.88124,     0.88523,     0.88755,     0.89068,     0.89134,     0.89206,     0.89283,     0.89508,     0.89689,      0.8974,     0.89854,     0.90181,     0.90406,     0.90488,     0.90625,     0.90702,     0.90758,     0.90811,     0.90861,     0.90918,\n",
      "            0.91016,     0.91074,     0.91131,     0.91219,     0.91282,     0.91313,     0.91344,     0.91374,     0.91427,     0.91667,      0.9182,     0.91916,     0.91987,     0.92064,      0.9216,     0.92222,     0.92276,      0.9234,     0.92415,     0.92602,     0.92678,     0.92768,     0.92744,\n",
      "            0.92752,     0.92831,     0.92896,     0.92978,     0.93229,     0.93269,     0.93309,     0.93349,     0.93475,     0.93758,     0.93915,     0.93945,     0.93974,     0.94004,     0.94032,      0.9404,     0.94048,     0.94055,     0.94063,     0.94071,     0.94078,     0.94086,     0.94094,\n",
      "            0.94101,     0.94109,     0.94116,     0.94124,     0.94132,     0.94139,     0.94147,     0.94155,     0.94162,      0.9417,     0.94179,     0.94189,     0.94198,     0.94208,     0.94217,     0.94227,     0.94236,     0.94246,     0.94255,     0.94265,     0.94274,     0.94284,     0.94293,\n",
      "            0.94302,      0.9442,     0.94539,     0.94588,     0.94597,     0.94605,     0.94614,     0.94623,     0.94632,      0.9464,     0.94649,     0.94658,     0.94667,     0.94675,     0.94684,     0.94693,     0.94701,      0.9471,     0.94719,     0.94726,     0.94733,      0.9474,     0.94747,\n",
      "            0.94754,     0.94761,     0.94768,     0.94775,     0.94782,     0.94788,     0.94795,     0.94802,     0.94809,     0.94816,     0.94823,      0.9483,     0.94837,     0.94844,      0.9485,     0.94857,      0.9488,     0.94915,      0.9495,     0.94985,     0.95147,     0.95179,     0.95211,\n",
      "            0.95243,     0.95275,     0.95325,      0.9538,     0.95448,     0.95556,     0.95529,     0.95494,     0.95459,     0.95424,     0.95416,     0.95431,     0.95446,     0.95461,     0.95476,     0.95491,     0.95506,     0.95521,     0.95536,     0.95551,     0.95563,     0.95576,     0.95589,\n",
      "            0.95601,     0.95614,     0.95627,     0.95639,     0.95652,     0.95665,     0.95677,      0.9569,     0.95704,     0.95719,     0.95733,     0.95747,     0.95761,     0.95776,      0.9579,     0.95804,     0.95819,     0.95833,     0.95845,     0.95858,      0.9587,     0.95883,     0.95895,\n",
      "            0.95907,      0.9592,     0.95932,     0.95945,     0.95957,      0.9597,     0.95978,     0.95981,     0.95984,     0.95987,     0.95991,     0.95994,     0.95997,        0.96,     0.96003,     0.96007,      0.9601,     0.96013,     0.96016,     0.96019,     0.96023,     0.96026,     0.96029,\n",
      "            0.96032,     0.96036,     0.96039,     0.96042,     0.96045,     0.96048,     0.96052,     0.96055,     0.96058,     0.96061,     0.96064,     0.96068,     0.96071,     0.96074,     0.96077,     0.96081,     0.96084,     0.96087,      0.9609,     0.96093,     0.96097,       0.961,     0.96103,\n",
      "            0.96106,     0.96109,     0.96113,     0.96116,     0.96119,     0.96155,     0.96195,     0.96234,     0.96275,     0.96318,     0.96361,     0.96405,     0.96414,     0.96422,      0.9643,     0.96437,     0.96445,     0.96453,      0.9646,     0.96468,     0.96476,     0.96483,     0.96491,\n",
      "            0.96499,     0.96506,     0.96514,     0.96522,     0.96529,     0.96537,     0.96545,      0.9655,     0.96528,     0.96506,     0.96483,     0.96461,     0.96438,     0.96416,     0.96398,      0.9641,     0.96422,     0.96435,     0.96447,     0.96459,     0.96471,     0.96483,     0.96496,\n",
      "            0.96508,      0.9652,     0.96532,     0.96551,      0.9659,     0.96629,     0.96668,     0.96684,     0.96678,     0.96673,     0.96667,     0.96662,     0.96656,     0.96651,     0.96645,     0.96639,     0.96634,     0.96628,     0.96623,     0.96617,     0.96612,     0.96606,     0.96601,\n",
      "            0.96595,     0.96589,     0.96584,     0.96578,     0.96573,     0.96567,     0.96562,     0.96556,     0.96551,     0.96545,     0.96539,     0.96534,     0.96536,     0.96548,      0.9656,     0.96571,     0.96583,     0.96595,     0.96606,     0.96618,      0.9663,     0.96641,     0.96653,\n",
      "            0.96665,     0.96676,     0.96784,     0.96808,     0.96786,     0.96763,     0.96741,     0.96718,     0.96696,     0.96673,     0.96683,     0.96706,      0.9673,     0.96753,     0.96776,     0.96799,     0.96815,     0.96819,     0.96824,     0.96828,     0.96833,     0.96837,     0.96841,\n",
      "            0.96846,      0.9685,     0.96855,     0.96859,     0.96863,     0.96868,     0.96872,     0.96877,     0.96881,     0.96885,      0.9689,     0.96894,     0.96899,     0.96903,     0.96907,     0.96912,     0.96916,      0.9692,     0.96925,     0.96929,     0.96934,     0.96938,     0.96942,\n",
      "            0.96947,     0.96951,     0.96956,      0.9696,     0.96978,     0.96999,     0.97019,     0.97039,      0.9706,      0.9708,       0.971,     0.97252,     0.97238,     0.97224,     0.97211,     0.97197,     0.97183,      0.9717,     0.97156,     0.97142,     0.97129,     0.97115,     0.97101,\n",
      "            0.97121,     0.97147,     0.97172,     0.97198,     0.97224,     0.97248,     0.97258,     0.97267,     0.97276,     0.97285,     0.97295,     0.97304,     0.97313,     0.97323,     0.97332,     0.97341,      0.9735,      0.9736,     0.97369,     0.97378,     0.97388,     0.97397,     0.97393,\n",
      "            0.97389,     0.97386,     0.97382,     0.97379,     0.97375,     0.97371,     0.97368,     0.97364,     0.97361,     0.97357,     0.97353,      0.9735,     0.97346,     0.97343,     0.97339,     0.97335,     0.97332,     0.97328,     0.97324,     0.97321,     0.97317,     0.97314,      0.9731,\n",
      "            0.97306,     0.97303,     0.97299,     0.97296,     0.97292,     0.97288,     0.97285,     0.97281,     0.97278,     0.97274,      0.9727,     0.97267,     0.97263,      0.9726,     0.97256,     0.97252,     0.97249,     0.97245,     0.97241,     0.97237,     0.97232,     0.97226,      0.9722,\n",
      "            0.97215,     0.97209,     0.97204,     0.97198,     0.97193,     0.97187,     0.97181,     0.97176,      0.9717,     0.97165,     0.97159,     0.97154,     0.97148,     0.97142,     0.97137,     0.97131,     0.97126,      0.9712,     0.97114,     0.97109,     0.97103,     0.97098,     0.97092,\n",
      "            0.97087,     0.97083,     0.97097,     0.97112,     0.97126,      0.9714,     0.97155,     0.97169,     0.97184,     0.97198,     0.97213,     0.97227,     0.97313,     0.97379,     0.97375,     0.97371,     0.97367,     0.97363,     0.97359,     0.97355,     0.97351,     0.97347,     0.97343,\n",
      "            0.97339,     0.97335,     0.97331,     0.97327,     0.97323,     0.97319,     0.97315,     0.97311,     0.97307,     0.97303,     0.97299,     0.97295,     0.97291,     0.97287,     0.97283,     0.97279,     0.97275,     0.97271,     0.97267,     0.97263,     0.97259,     0.97255,     0.97251,\n",
      "            0.97247,     0.97243,     0.97239,     0.97236,     0.97232,     0.97228,     0.97224,     0.97228,     0.97237,     0.97246,     0.97255,     0.97264,     0.97272,     0.97281,      0.9729,     0.97299,     0.97308,     0.97317,     0.97325,     0.97334,     0.97343,     0.97352,     0.97361,\n",
      "            0.97369,     0.97368,      0.9736,     0.97353,     0.97345,     0.97338,     0.97331,     0.97323,     0.97316,     0.97308,     0.97301,     0.97294,     0.97286,     0.97279,     0.97271,     0.97264,     0.97257,     0.97249,     0.97242,     0.97234,     0.97227,     0.97219,     0.97215,\n",
      "            0.97224,     0.97232,      0.9724,     0.97249,     0.97257,     0.97266,     0.97274,     0.97282,     0.97291,     0.97299,     0.97307,     0.97316,     0.97324,     0.97332,     0.97341,     0.97349,     0.97357,     0.97363,     0.97357,     0.97351,     0.97345,     0.97339,     0.97333,\n",
      "            0.97326,      0.9732,     0.97314,     0.97308,     0.97302,     0.97296,      0.9729,     0.97283,     0.97277,     0.97271,     0.97265,     0.97259,     0.97253,     0.97247,      0.9724,     0.97234,     0.97228,     0.97222,     0.97216,      0.9721,     0.97203,     0.97194,     0.97185,\n",
      "            0.97176,     0.97167,     0.97158,     0.97149,      0.9714,     0.97131,     0.97122,     0.97113,     0.97104,     0.97095,     0.97086,     0.97077,     0.97068,     0.97059,      0.9705,     0.97041,     0.97033,     0.97025,     0.97016,     0.97008,        0.97,     0.96992,     0.96984,\n",
      "            0.96975,     0.96967,     0.96959,     0.96951,     0.96943,     0.96934,     0.96926,     0.96918,      0.9691,     0.96901,     0.96893,     0.96885,     0.96882,     0.96879,     0.96876,     0.96873,     0.96871,     0.96868,     0.96865,     0.96862,     0.96859,     0.96856,     0.96853,\n",
      "            0.96851,     0.96848,     0.96845,     0.96842,     0.96839,     0.96836,     0.96833,      0.9683,     0.96828,     0.96825,     0.96822,     0.96819,     0.96816,     0.96813,      0.9681,     0.96808,     0.96805,     0.96802,     0.96799,     0.96796,     0.96793,      0.9679,     0.96787,\n",
      "            0.96785,     0.96782,     0.96779,     0.96776,     0.96773,      0.9677,     0.96767,     0.96765,     0.96762,     0.96759,     0.96756,     0.96753,      0.9675,     0.96747,     0.96744,     0.96742,     0.96739,     0.96736,     0.96733,      0.9673,     0.96727,     0.96724,      0.9672,\n",
      "            0.96715,      0.9671,     0.96706,     0.96701,     0.96696,     0.96691,     0.96687,     0.96682,     0.96677,     0.96672,     0.96667,     0.96663,     0.96658,     0.96653,     0.96648,     0.96643,     0.96639,     0.96634,     0.96629,     0.96624,      0.9662,     0.96615,      0.9661,\n",
      "            0.96605,       0.966,     0.96596,     0.96591,     0.96586,     0.96581,     0.96576,     0.96572,     0.96567,     0.96561,     0.96544,     0.96528,     0.96511,     0.96495,     0.96478,     0.96461,     0.96445,     0.96428,     0.96411,      0.9637,      0.9628,      0.9623,     0.96215,\n",
      "              0.962,     0.96184,     0.96169,     0.96154,     0.96139,     0.96123,     0.96108,     0.96093,     0.96078,     0.96046,     0.96012,     0.95978,     0.95943,     0.95909,      0.9587,     0.95831,     0.95792,     0.95754,     0.95742,     0.95735,     0.95728,     0.95721,     0.95715,\n",
      "            0.95708,     0.95701,     0.95694,     0.95687,      0.9568,     0.95673,     0.95666,     0.95659,     0.95653,     0.95646,     0.95639,     0.95632,     0.95625,     0.95618,     0.95611,     0.95604,     0.95597,      0.9559,     0.95583,     0.95575,     0.95567,     0.95559,     0.95551,\n",
      "            0.95542,     0.95534,     0.95526,     0.95518,      0.9551,     0.95501,     0.95493,     0.95485,     0.95477,     0.95469,      0.9546,     0.95452,     0.95444,     0.95436,     0.95427,     0.95419,     0.95342,      0.9526,     0.95322,     0.95396,      0.9523,     0.95164,     0.95099,\n",
      "            0.95063,     0.95048,     0.95034,     0.95019,     0.95004,      0.9499,     0.94975,      0.9496,     0.94946,     0.94931,     0.94916,     0.94887,     0.94802,     0.94733,     0.94718,     0.94702,     0.94687,     0.94672,     0.94656,     0.94641,     0.94625,      0.9461,     0.94595,\n",
      "            0.94579,     0.94547,     0.94477,     0.94408,     0.94357,     0.94308,     0.94259,     0.94224,     0.94209,     0.94194,     0.94179,     0.94164,     0.94149,     0.94134,     0.94119,     0.94104,     0.94089,     0.94074,     0.94057,     0.94026,     0.93994,     0.93963,     0.93932,\n",
      "            0.93901,     0.93855,     0.93801,     0.93748,     0.93563,     0.93369,     0.93348,     0.93328,     0.93307,     0.93287,     0.93266,     0.93246,     0.93225,     0.93205,     0.93091,     0.93012,     0.92975,     0.92937,     0.92899,     0.92861,     0.92785,     0.92704,     0.92642,\n",
      "            0.92587,     0.92532,     0.92457,     0.92364,     0.92306,     0.92266,     0.92225,     0.92185,     0.91992,     0.91717,     0.91495,     0.91093,     0.90914,     0.90547,     0.90268,     0.90028,     0.89296,     0.88859,     0.88788,     0.88716,     0.88478,     0.88096,     0.87128,\n",
      "            0.86651,     0.85969,      0.8549,     0.85019,     0.84661,     0.83566,     0.83189,     0.82638,     0.82132,     0.81233,     0.79664,     0.78326,     0.76438,     0.74477,      0.7226,     0.71459,     0.70248,     0.67917,     0.65237,     0.61161,     0.58391,     0.55535,     0.51193,\n",
      "            0.46988,     0.45083,     0.40531,      0.3653,     0.33792,     0.30241,     0.27044,     0.23761,     0.19498,     0.15749,     0.14027,     0.12199,      0.1008,    0.086527,     0.06686,    0.060197,    0.036164,    0.011753,    0.010379,   0.0090037,   0.0076261,   0.0062467,           0,\n",
      "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.39141,     0.39241,     0.51722,     0.56946,     0.61086,     0.64229,     0.66269,     0.68307,     0.69721,     0.71395,     0.71915,      0.7327,     0.73659,     0.73885,     0.74998,     0.75964,      0.7668,     0.77278,     0.77564,     0.77783,     0.77907,     0.78161,     0.78443,\n",
      "            0.79081,     0.79198,     0.79422,     0.79736,     0.80391,     0.80774,     0.81295,     0.81405,     0.81526,     0.81654,     0.82032,     0.82336,     0.82421,     0.82615,     0.83169,     0.83552,     0.83692,     0.83927,      0.8406,     0.84156,     0.84246,     0.84332,     0.84431,\n",
      "            0.84826,     0.84925,     0.85025,     0.85178,     0.85288,     0.85342,     0.85396,      0.8545,     0.85542,     0.85963,     0.86233,     0.86401,     0.86528,     0.86663,     0.86834,     0.86944,     0.87041,     0.87154,     0.87288,     0.87623,     0.87759,     0.87919,     0.88024,\n",
      "            0.88135,     0.88279,     0.88396,     0.88544,        0.89,     0.89073,     0.89146,     0.89219,      0.8945,     0.89971,     0.90259,     0.90314,     0.90369,     0.90424,     0.90477,     0.90491,     0.90505,     0.90519,     0.90534,     0.90548,     0.90562,     0.90576,      0.9059,\n",
      "            0.90604,     0.90619,     0.90633,     0.90647,     0.90661,     0.90675,     0.90689,     0.90703,     0.90718,     0.90732,      0.9075,     0.90767,     0.90785,     0.90802,      0.9082,     0.90838,     0.90855,     0.90873,      0.9089,     0.90908,     0.90926,     0.90943,     0.90961,\n",
      "            0.90978,     0.91198,     0.91419,     0.91511,     0.91527,     0.91544,      0.9156,     0.91577,     0.91593,     0.91609,     0.91626,     0.91642,     0.91658,     0.91675,     0.91691,     0.91708,     0.91724,      0.9174,     0.91757,     0.91771,     0.91784,     0.91797,      0.9181,\n",
      "            0.91822,     0.91835,     0.91848,     0.91861,     0.91874,     0.91887,       0.919,     0.91913,     0.91926,     0.91939,     0.91952,     0.91965,     0.91978,     0.91991,     0.92004,     0.92017,     0.92059,     0.92125,     0.92191,     0.92257,     0.92564,     0.92624,     0.92685,\n",
      "            0.92745,     0.92806,     0.92902,     0.93006,     0.93135,     0.93341,     0.93348,     0.93344,      0.9334,     0.93335,     0.93349,     0.93378,     0.93407,     0.93436,     0.93464,     0.93493,     0.93522,     0.93551,      0.9358,     0.93608,     0.93632,     0.93657,     0.93681,\n",
      "            0.93706,      0.9373,     0.93754,     0.93779,     0.93803,     0.93827,     0.93852,     0.93876,     0.93903,     0.93931,     0.93958,     0.93986,     0.94013,     0.94041,     0.94068,     0.94096,     0.94124,     0.94151,     0.94175,     0.94199,     0.94223,     0.94247,     0.94271,\n",
      "            0.94295,     0.94319,     0.94343,     0.94367,     0.94391,     0.94415,     0.94431,     0.94437,     0.94444,      0.9445,     0.94456,     0.94462,     0.94468,     0.94475,     0.94481,     0.94487,     0.94493,       0.945,     0.94506,     0.94512,     0.94518,     0.94525,     0.94531,\n",
      "            0.94537,     0.94543,     0.94549,     0.94556,     0.94562,     0.94568,     0.94574,     0.94581,     0.94587,     0.94593,     0.94599,     0.94606,     0.94612,     0.94618,     0.94624,      0.9463,     0.94637,     0.94643,     0.94649,     0.94655,     0.94662,     0.94668,     0.94674,\n",
      "             0.9468,     0.94687,     0.94693,     0.94699,     0.94705,     0.94775,     0.94852,     0.94929,     0.95008,     0.95093,     0.95177,     0.95261,      0.9528,     0.95295,      0.9531,     0.95325,      0.9534,     0.95355,      0.9537,     0.95385,       0.954,     0.95415,      0.9543,\n",
      "            0.95445,      0.9546,     0.95475,      0.9549,     0.95505,      0.9552,     0.95535,     0.95549,     0.95547,     0.95545,     0.95543,     0.95541,     0.95539,     0.95537,     0.95539,     0.95563,     0.95587,     0.95611,     0.95635,     0.95659,     0.95683,     0.95707,     0.95731,\n",
      "            0.95755,     0.95779,     0.95803,      0.9584,     0.95917,     0.95994,     0.96071,     0.96108,     0.96107,     0.96107,     0.96106,     0.96106,     0.96105,     0.96105,     0.96105,     0.96104,     0.96104,     0.96103,     0.96103,     0.96103,     0.96102,     0.96102,     0.96101,\n",
      "            0.96101,       0.961,       0.961,       0.961,     0.96099,     0.96099,     0.96098,     0.96098,     0.96098,     0.96097,     0.96097,     0.96096,     0.96107,      0.9613,     0.96153,     0.96176,     0.96199,     0.96223,     0.96246,     0.96269,     0.96292,     0.96315,     0.96338,\n",
      "            0.96361,     0.96385,     0.96598,     0.96676,     0.96674,     0.96673,     0.96671,      0.9667,     0.96669,     0.96667,       0.967,     0.96746,     0.96792,     0.96839,     0.96885,     0.96932,     0.96964,     0.96973,     0.96982,      0.9699,     0.96999,     0.97008,     0.97017,\n",
      "            0.97026,     0.97034,     0.97043,     0.97052,     0.97061,      0.9707,     0.97079,     0.97087,     0.97096,     0.97105,     0.97114,     0.97123,     0.97132,      0.9714,     0.97149,     0.97158,     0.97167,     0.97176,     0.97184,     0.97193,     0.97202,     0.97211,      0.9722,\n",
      "            0.97229,     0.97237,     0.97246,     0.97255,     0.97292,     0.97333,     0.97374,     0.97415,     0.97456,     0.97497,     0.97538,     0.97853,     0.97852,     0.97851,     0.97851,      0.9785,      0.9785,     0.97849,     0.97849,     0.97848,     0.97847,     0.97847,     0.97846,\n",
      "             0.9789,     0.97943,     0.97995,     0.98047,     0.98099,     0.98149,     0.98168,     0.98187,     0.98206,     0.98225,     0.98244,     0.98263,     0.98282,     0.98301,      0.9832,     0.98339,     0.98358,     0.98377,     0.98396,     0.98414,     0.98433,     0.98452,     0.98452,\n",
      "            0.98452,     0.98452,     0.98452,     0.98451,     0.98451,     0.98451,     0.98451,     0.98451,     0.98451,     0.98451,     0.98451,     0.98451,      0.9845,      0.9845,      0.9845,      0.9845,      0.9845,      0.9845,      0.9845,      0.9845,      0.9845,     0.98449,     0.98449,\n",
      "            0.98449,     0.98449,     0.98449,     0.98449,     0.98449,     0.98449,     0.98449,     0.98448,     0.98448,     0.98448,     0.98448,     0.98448,     0.98448,     0.98448,     0.98448,     0.98448,     0.98447,     0.98447,     0.98447,     0.98447,     0.98447,     0.98447,     0.98447,\n",
      "            0.98446,     0.98446,     0.98446,     0.98446,     0.98446,     0.98446,     0.98445,     0.98445,     0.98445,     0.98445,     0.98445,     0.98445,     0.98444,     0.98444,     0.98444,     0.98444,     0.98444,     0.98444,     0.98443,     0.98443,     0.98443,     0.98443,     0.98443,\n",
      "            0.98443,     0.98445,     0.98475,     0.98504,     0.98534,     0.98564,     0.98594,     0.98623,     0.98653,     0.98683,     0.98713,     0.98743,      0.9892,      0.9906,     0.99059,     0.99059,     0.99059,     0.99059,     0.99059,     0.99059,     0.99059,     0.99059,     0.99059,\n",
      "            0.99059,     0.99059,     0.99059,     0.99059,     0.99058,     0.99058,     0.99058,     0.99058,     0.99058,     0.99058,     0.99058,     0.99058,     0.99058,     0.99058,     0.99058,     0.99058,     0.99058,     0.99058,     0.99057,     0.99057,     0.99057,     0.99057,     0.99057,\n",
      "            0.99057,     0.99057,     0.99057,     0.99057,     0.99057,     0.99057,     0.99057,     0.99069,     0.99087,     0.99106,     0.99124,     0.99142,     0.99161,     0.99179,     0.99197,     0.99216,     0.99234,     0.99253,     0.99271,     0.99289,     0.99308,     0.99326,     0.99344,\n",
      "            0.99363,     0.99369,     0.99369,     0.99369,     0.99369,     0.99369,     0.99369,     0.99368,     0.99368,     0.99368,     0.99368,     0.99368,     0.99368,     0.99368,     0.99368,     0.99368,     0.99368,     0.99368,     0.99367,     0.99367,     0.99367,     0.99367,     0.99371,\n",
      "            0.99388,     0.99406,     0.99423,     0.99441,     0.99458,     0.99476,     0.99493,     0.99511,     0.99528,     0.99546,     0.99563,     0.99581,     0.99598,     0.99616,     0.99633,     0.99651,     0.99668,     0.99683,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,\n",
      "            0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99682,     0.99681,     0.99681,\n",
      "            0.99681,     0.99681,     0.99681,     0.99681,     0.99681,     0.99681,     0.99681,     0.99681,     0.99681,     0.99681,     0.99681,     0.99681,     0.99681,     0.99681,     0.99681,      0.9968,      0.9968,      0.9968,      0.9968,      0.9968,      0.9968,      0.9968,      0.9968,\n",
      "             0.9968,      0.9968,      0.9968,      0.9968,      0.9968,      0.9968,      0.9968,      0.9968,      0.9968,      0.9968,      0.9968,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,\n",
      "            0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,\n",
      "            0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99679,     0.99678,     0.99678,     0.99678,     0.99678,\n",
      "            0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,\n",
      "            0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99678,     0.99677,     0.99677,     0.99677,     0.99677,     0.99677,     0.99677,     0.99677,     0.99677,     0.99677,     0.99677,     0.99677,     0.99676,     0.99676,     0.99676,     0.99675,     0.99675,\n",
      "            0.99675,     0.99675,     0.99675,     0.99675,     0.99675,     0.99675,     0.99674,     0.99674,     0.99674,     0.99674,     0.99674,     0.99674,     0.99673,     0.99673,     0.99673,     0.99673,     0.99672,     0.99672,     0.99672,     0.99672,     0.99672,     0.99672,     0.99672,\n",
      "            0.99672,     0.99672,     0.99672,     0.99672,     0.99672,     0.99672,     0.99672,     0.99672,     0.99672,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,\n",
      "            0.99671,     0.99671,     0.99671,     0.99671,     0.99671,     0.99671,      0.9967,      0.9967,      0.9967,      0.9967,      0.9967,      0.9967,      0.9967,      0.9967,      0.9967,      0.9967,     0.99669,     0.99669,     0.99819,     0.99982,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
      "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.99394,     0.99394,     0.99091,     0.99091,     0.99091,     0.99091,     0.99091,     0.99091,     0.99091,     0.98788,     0.98788,     0.98788,     0.98788,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,\n",
      "            0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,\n",
      "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.97998,\n",
      "            0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,\n",
      "            0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,\n",
      "            0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,\n",
      "            0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,\n",
      "            0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97879,     0.97814,     0.97745,     0.97676,     0.97607,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,\n",
      "            0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,\n",
      "            0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,\n",
      "            0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,\n",
      "            0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,\n",
      "            0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97576,     0.97573,     0.97529,     0.97486,     0.97442,     0.97398,     0.97355,     0.97311,     0.97273,     0.97273,     0.97273,     0.97273,     0.97273,     0.97273,     0.97273,     0.97273,     0.97273,\n",
      "            0.97273,     0.97273,     0.97273,     0.97273,     0.97273,     0.97273,     0.97273,     0.97267,     0.97256,     0.97245,     0.97235,     0.97224,     0.97213,     0.97202,     0.97191,     0.97181,      0.9717,     0.97159,     0.97148,     0.97137,     0.97127,     0.97116,     0.97105,\n",
      "            0.97094,     0.97083,     0.97073,     0.97062,     0.97051,      0.9704,     0.97029,     0.97019,     0.97008,     0.96997,     0.96986,     0.96975,      0.9697,      0.9697,      0.9697,      0.9697,      0.9697,      0.9697,      0.9697,      0.9697,      0.9697,      0.9697,      0.9697,\n",
      "             0.9697,      0.9697,      0.9697,     0.96942,     0.96898,     0.96854,      0.9681,     0.96767,     0.96723,     0.96679,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,\n",
      "            0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,\n",
      "            0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96658,     0.96632,     0.96605,     0.96579,     0.96553,     0.96526,       0.965,     0.96473,     0.96447,      0.9642,     0.96394,     0.96368,\n",
      "            0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96364,     0.96357,\n",
      "             0.9635,     0.96343,     0.96336,     0.96329,     0.96322,     0.96315,     0.96308,     0.96301,     0.96294,     0.96287,      0.9628,     0.96273,     0.96266,     0.96259,     0.96252,     0.96245,     0.96238,     0.96232,     0.96225,     0.96218,     0.96211,     0.96204,     0.96197,\n",
      "             0.9619,     0.96183,     0.96176,     0.96169,     0.96162,     0.96155,     0.96148,     0.96141,     0.96134,     0.96127,      0.9612,     0.96113,     0.96107,       0.961,     0.96093,     0.96086,     0.96079,     0.96072,     0.96065,     0.96056,     0.96046,     0.96035,     0.96024,\n",
      "            0.96014,     0.96003,     0.95992,     0.95982,     0.95971,      0.9596,     0.95949,     0.95939,     0.95928,     0.95917,     0.95907,     0.95896,     0.95885,     0.95874,     0.95864,     0.95853,     0.95842,     0.95832,     0.95821,      0.9581,       0.958,     0.95789,     0.95778,\n",
      "            0.95767,     0.95758,     0.95758,     0.95758,     0.95758,     0.95758,     0.95758,     0.95758,     0.95758,     0.95758,     0.95758,     0.95758,     0.95758,     0.95755,     0.95747,     0.95739,     0.95732,     0.95724,     0.95716,     0.95709,     0.95701,     0.95694,     0.95686,\n",
      "            0.95678,     0.95671,     0.95663,     0.95655,     0.95648,      0.9564,     0.95633,     0.95625,     0.95617,      0.9561,     0.95602,     0.95594,     0.95587,     0.95579,     0.95572,     0.95564,     0.95556,     0.95549,     0.95541,     0.95533,     0.95526,     0.95518,      0.9551,\n",
      "            0.95503,     0.95495,     0.95488,      0.9548,     0.95472,     0.95465,     0.95457,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,     0.95455,\n",
      "            0.95455,     0.95445,     0.95431,     0.95417,     0.95403,     0.95389,     0.95375,     0.95361,     0.95346,     0.95332,     0.95318,     0.95304,      0.9529,     0.95276,     0.95262,     0.95247,     0.95233,     0.95219,     0.95205,     0.95191,     0.95177,     0.95163,     0.95152,\n",
      "            0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,     0.95152,      0.9515,     0.95138,     0.95126,     0.95114,     0.95103,     0.95091,\n",
      "            0.95079,     0.95068,     0.95056,     0.95044,     0.95033,     0.95021,     0.95009,     0.94998,     0.94986,     0.94974,     0.94962,     0.94951,     0.94939,     0.94927,     0.94916,     0.94904,     0.94892,     0.94881,     0.94869,     0.94857,     0.94844,     0.94827,      0.9481,\n",
      "            0.94793,     0.94776,     0.94759,     0.94742,     0.94725,     0.94708,      0.9469,     0.94673,     0.94656,     0.94639,     0.94622,     0.94605,     0.94588,     0.94571,     0.94554,     0.94538,     0.94522,     0.94507,     0.94491,     0.94476,      0.9446,     0.94445,     0.94429,\n",
      "            0.94414,     0.94398,     0.94383,     0.94367,     0.94352,     0.94336,     0.94321,     0.94305,     0.94289,     0.94274,     0.94258,     0.94243,     0.94237,     0.94232,     0.94226,     0.94221,     0.94216,      0.9421,     0.94205,     0.94199,     0.94194,     0.94189,     0.94183,\n",
      "            0.94178,     0.94172,     0.94167,     0.94162,     0.94156,     0.94151,     0.94145,      0.9414,     0.94135,     0.94129,     0.94124,     0.94119,     0.94113,     0.94108,     0.94102,     0.94097,     0.94092,     0.94086,     0.94081,     0.94075,      0.9407,     0.94065,     0.94059,\n",
      "            0.94054,     0.94048,     0.94043,     0.94038,     0.94032,     0.94027,     0.94021,     0.94016,     0.94011,     0.94005,        0.94,     0.93994,     0.93989,     0.93984,     0.93978,     0.93973,     0.93967,     0.93962,     0.93957,     0.93951,     0.93946,      0.9394,     0.93932,\n",
      "            0.93923,     0.93914,     0.93905,     0.93896,     0.93887,     0.93878,     0.93869,      0.9386,     0.93851,     0.93842,     0.93833,     0.93824,     0.93815,     0.93806,     0.93797,     0.93788,     0.93779,      0.9377,     0.93761,     0.93752,     0.93743,     0.93734,     0.93725,\n",
      "            0.93716,     0.93707,     0.93698,     0.93689,      0.9368,     0.93671,     0.93662,     0.93653,     0.93644,     0.93633,     0.93602,     0.93571,      0.9354,     0.93509,     0.93478,     0.93447,     0.93416,     0.93385,     0.93354,     0.93276,     0.93109,     0.93015,     0.92987,\n",
      "            0.92958,      0.9293,     0.92902,     0.92873,     0.92845,     0.92817,     0.92788,      0.9276,     0.92731,     0.92673,     0.92609,     0.92546,     0.92482,     0.92418,     0.92346,     0.92275,     0.92203,     0.92132,      0.9211,     0.92098,     0.92085,     0.92072,     0.92059,\n",
      "            0.92047,     0.92034,     0.92021,     0.92009,     0.91996,     0.91983,      0.9197,     0.91958,     0.91945,     0.91932,      0.9192,     0.91907,     0.91894,     0.91881,     0.91869,     0.91856,     0.91843,     0.91831,     0.91818,     0.91803,     0.91788,     0.91773,     0.91758,\n",
      "            0.91742,     0.91727,     0.91712,     0.91697,     0.91682,     0.91667,     0.91652,     0.91637,     0.91622,     0.91607,     0.91592,     0.91577,     0.91561,     0.91546,     0.91531,     0.91516,     0.91375,     0.91225,     0.91212,     0.91212,     0.90894,     0.90775,     0.90656,\n",
      "            0.90591,     0.90564,     0.90537,     0.90511,     0.90484,     0.90457,     0.90431,     0.90404,     0.90378,     0.90351,     0.90324,     0.90272,     0.90118,     0.89993,     0.89966,     0.89938,      0.8991,     0.89882,     0.89855,     0.89827,     0.89799,     0.89771,     0.89744,\n",
      "            0.89716,     0.89657,     0.89533,     0.89408,     0.89316,     0.89229,     0.89142,      0.8908,     0.89053,     0.89026,     0.88999,     0.88972,     0.88945,     0.88919,     0.88892,     0.88865,     0.88838,     0.88811,      0.8878,     0.88725,     0.88669,     0.88614,     0.88558,\n",
      "            0.88503,     0.88421,     0.88326,     0.88231,     0.87904,     0.87562,     0.87526,      0.8749,     0.87454,     0.87418,     0.87382,     0.87346,      0.8731,     0.87274,     0.87075,     0.86938,     0.86872,     0.86805,     0.86739,     0.86673,      0.8654,       0.864,     0.86293,\n",
      "            0.86198,     0.86103,     0.85971,     0.85812,     0.85712,     0.85642,     0.85573,     0.85503,     0.85171,     0.84701,     0.84324,     0.83644,     0.83341,     0.82726,     0.82262,     0.81864,     0.80661,     0.79952,     0.79836,     0.79721,     0.79336,     0.78724,     0.77193,\n",
      "            0.76446,     0.75391,     0.74657,     0.73941,     0.73402,     0.71771,     0.71217,     0.70413,     0.69681,     0.68396,     0.66202,     0.64373,     0.61863,     0.59334,     0.56568,     0.55593,     0.54141,      0.5142,     0.48408,     0.44052,     0.41234,     0.38442,     0.34402,\n",
      "            0.30709,     0.29101,     0.25416,     0.22346,     0.20331,     0.17814,     0.15637,     0.13482,     0.10802,    0.085477,    0.075425,    0.064959,    0.053075,     0.04522,    0.034586,    0.031033,    0.018415,   0.0059113,   0.0052167,   0.0045222,   0.0038277,   0.0031331,           0,\n",
      "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
      "fitness: np.float64(0.965304758466665)\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.96254])\n",
      "names: {0: 'lego'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': np.float64(0.9925254619660677), 'metrics/recall(B)': np.float64(0.9545454545454546), 'metrics/mAP50(B)': np.float64(0.9901656014451229), 'metrics/mAP50-95(B)': np.float64(0.9625424425801696), 'fitness': np.float64(0.965304758466665)}\n",
      "save_dir: PosixPath('runs/detect/train22')\n",
      "speed: {'preprocess': 0.3057098388671875, 'inference': 12.757058143615723, 'loss': 0.027451515197753906, 'postprocess': 1.5047383308410645}\n",
      "task: 'detect'\n"
     ]
    }
   ],
   "source": [
    "results = model.val(data='./lego.yaml', imgsz=640)\n",
    "print(\"Validation results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement google-colab (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for google-colab\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
